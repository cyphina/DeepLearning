# -*- coding: utf-8 -*-
"""DataPoisoningAndroid

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wXocxpWia22_8bHw5g_i6WyP3ZNBTm3l
"""

import os
import numpy as np
import pandas as pd
import timeit
import datetime
import json

from enum import Enum
from functools import partial
from nltk.tokenize.regexp import regexp_tokenize
from sklearn.model_selection import StratifiedShuffleSplit, cross_validate
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import confusion_matrix

!pip install tensorflow-gpu==2.0.0-alpha0
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Dropout, concatenate
from tensorflow.keras.callbacks import LambdaCallback
from tensorflow.keras import Model

from google.colab import drive
drive.mount('/content/gdrive')

"""CONSTANTS"""

#File paths
PROJECT_PATH = r"/content/gdrive/My Drive/ML/APKAnalysis"
DATA_PATH = os.path.join(PROJECT_PATH, r"Data/subsets/")
GOOD_PATH = os.path.join(DATA_PATH, r"benign_badging_{}000h.txt")
BAD_PATH = os.path.join(DATA_PATH, r"mal_badging_{}000h.txt")
RESULT_PATH = os.path.join(PROJECT_PATH, "Results")
CHKPT_PATH = os.path.join(PROJECT_PATH, "Checkpoints")
#Data params
RANDOM_SEED = 42
SUBSET_COUNT = 4
TRAIN_RATIO = .8
class EMixStrategy(Enum):
  NoStrategy = 0
  Random = 1
  Most_Occuring=2
  Gradients=3
  Weights=4
#Model params
NEURONS_PER_LAYER = 32
DROPOUT_RATE = .1
INPUT_RATIO = .125 #How large should layers in the second network in the dual newtork be compared to the first 
BATCH_SIZE=128
EPOCHS=32

if not os.path.exists(RESULT_PATH):
  os.makedirs(RESULT_PATH)

#Load files with permissions from disk
ben_samples = []
mal_samples = []

for x in range(SUBSET_COUNT):
  with open(GOOD_PATH.format(x+1), encoding='utf-8') as f:
    ben_samples += f.readlines()
  with open(BAD_PATH.format(x+1), encoding='utf-8') as f:
    mal_samples += f.readlines()
  
samples = ben_samples + mal_samples
len(samples)

#Add labels
labels = np.array([])
for x in ben_samples:
  labels = np.append(labels, 0)
for x in mal_samples:
  labels = np.append(labels, 1)

#Test out sample size
sampleSize = len(labels)
sampleSize

"""Data Preprocessing"""

#Regex expressions formatching 
perm_pattern = "(?:\w|\.)+(?:permission).(?:\w|\.)+"
feat_pattern = "(?:\w|\.)+(?:hardware).(?:\w|\.)+"
comb_pattern = "(?:\w|\.)+(?:hardware|permission).(?:\w|\.)+"

"""Generate a matrix where the columns are the permissions and features, the rows are the instances, and the values are 1 if the permission/feature is present or not"""

#Wordcount one-hot transformer
perm_vect = CountVectorizer(analyzer=partial(regexp_tokenize, pattern=perm_pattern))
feat_vect = CountVectorizer(analyzer=partial(regexp_tokenize, pattern=feat_pattern))
comb_vect = CountVectorizer(analyzer=partial(regexp_tokenize, pattern=comb_pattern))

#If we didn't preload the vocabulary we'd call this
#perm_input_sparse = perm_vect.fit_transform(samples)
#feat_input_sparse = feat_vect.fit_transform(samples)
#comb_input_sparse = comb_vect.fit_transform(samples)

"""Preload the generated vocab over the full dataset so we don't have to call fit on the CountVectorizer"""

#Load pregenerated vocabulary from file 
perm_vocab = json.load(open(os.path.join(PROJECT_PATH,'perm_vocab.json')))
feat_vocab = json.load(open(os.path.join(PROJECT_PATH,'feat_vocab.json')))
comb_vocab = json.load(open(os.path.join(PROJECT_PATH,'comb_vocab.json')))

#Set vocabulry before transformation
perm_vect.vocabulary_ = perm_vocab
feat_vect.vocabulary_ = feat_vocab
comb_vect.vocabulary_ = comb_vocab

#Generate the one-hot vectors now 
perm_input_sparse = perm_vect.transform(samples)
feat_input_sparse = feat_vect.transform(samples)
comb_input_sparse = comb_vect.transform(samples)

#To numpy array for easier use
perm_inputs = perm_input_sparse.toarray()
feat_inputs = feat_input_sparse.toarray()
comb_inputs = comb_input_sparse.toarray()

print(feat_inputs.shape, "\n", feat_inputs) #Shows us for each instances what features it has

perm_vocab_width = len(perm_inputs[0])
feat_vocab_width = len(feat_inputs[0])
comb_vocab_width = len(comb_inputs[0])

perm_vocab_width, feat_vocab_width, comb_vocab_width

sss = StratifiedShuffleSplit(n_splits=1, random_state=0, test_size=1-TRAIN_RATIO)
for train_index, test_index in sss.split(perm_inputs, labels):
  perm_train, perm_test = perm_inputs[train_index], perm_inputs[test_index]
  feat_train, feat_test = feat_inputs[train_index], feat_inputs[test_index]
  comb_train, comb_test = comb_inputs[train_index], comb_inputs[test_index]
  labels_train, labels_test = labels[train_index], labels[test_index]

len(perm_train), "\n", len(feat_train)

labels_train

"""Model Creation"""

#Model creation
def createModel():
  perm_input_layer = Input(shape=(perm_vocab_width,), name='permissions_input')
  h1_perm = Dense(NEURONS_PER_LAYER, activation='relu')(perm_input_layer)
  h1_perm = Dropout(DROPOUT_RATE)(h1_perm)
  h2_perm = Dense(NEURONS_PER_LAYER, activation='relu')(h1_perm)
  feat_input_layer = Input(shape=(feat_vocab_width,), name='features_input')
  h1_feat = Dense(int(NEURONS_PER_LAYER*INPUT_RATIO), activation='relu')(feat_input_layer)
  #Combine last layer of first network (handling permissions)with first layer of the second network (handling features)
  h1_comb = concatenate([h2_perm, h1_feat])
  h2_comb = Dense(int((NEURONS_PER_LAYER+(NEURONS_PER_LAYER*INPUT_RATIO))/2), activation='relu')(h1_comb)
  h2_comb = Dropout(DROPOUT_RATE)(h2_comb)
  h3_comb = Dense(int((NEURONS_PER_LAYER+(NEURONS_PER_LAYER*INPUT_RATIO))/2), activation='relu')(h2_comb)
  output = Dense(1, activation='sigmoid', name="output")(h3_comb)
  model = Model(inputs=[perm_input_layer, feat_input_layer], outputs=output)
  return model

"""Helper Functions"""

#Test but keep track of gradients
#Theory: We want to keep track of how much each feature contributes to the final model
#One proposed way is to average the gradients of the trained model for each input

loss_object = tf.keras.losses.BinaryCrossentropy()
optimizer = tf.compat.v1.train.AdamOptimizer()

@tf.function
def computeGrads(perms, feats, labels):
  with tf.GradientTape() as tape:
    predictions = model([perms, feats])
    loss = loss_object(labels, predictions)

  gradients = tape.gradient(loss, model.trainable_variables)
  input_gradient = gradients[0]
  return input_gradient

train_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_accuracy')
train_loss = tf.keras.metrics.Mean(name='train_loss')

@tf.function
def train_step(perms, feats, labels):
  with tf.GradientTape() as tape:
    predictions = model([perms, feats])
    loss = loss_object(labels, predictions)

  gradients = tape.gradient(loss, model.trainable_variables)
  optimizer.apply_gradients(zip(gradients,model.trainable_variables))
   
  train_loss(loss)
  train_accuracy(labels, predictions)

test_accuracy = tf.keras.metrics.BinaryAccuracy(name='test_accuracy')

@tf.function
def test_step(perms, feats, labels):
  predictions = model([perms, feats])
  accuracy = test_accuracy(labels, predictions)

#Metric functions
def calc_accuracy(cm):
    TP = float(cm[1][1])
    TN = float(cm[0][0])
    n_samples = cm.sum()
    return (TP+TN)/n_samples

def calc_precision(cm):
    TP = float(cm[1][1])
    FP = float(cm[0][1])
    return TP/(TP+FP)

def calc_recall(cm):
    TP = float(cm[1][1])
    FN = float(cm[1][0])
    return TP/(FN+TP)

def calc_f1(precision, recall):
    return 2*((precision*recall)/(precision+recall))
  
def save_results(data,mixStrategy):
  d = datetime.datetime.today()
  month = str( '%02d' % d.month)
  day = str('%02d' % d.day)
  hour = str('%02d' % d.hour)
  year = str('%02d' % d.year)
  min = str('%02d' % d.minute)

  df = pd.DataFrame(data)

  modelLabel = "mixP" + str(data[0]["label_mix_per"]) + "-size" + str(sampleSize) + "-strat" +  str(mixStrategy) + ".csv"
  modelPath = os.path.join(RESULT_PATH, modelLabel)
  print("Saving Results at " + modelPath + "!")
  
  isNewFile = not os.path.exists(modelPath)
  with open(modelPath, "a+") as f:
      df.to_csv(f, mode='a', header=isNewFile, index=False)

#Data poisoning label mixing formulas
def mixLabels(y_train, perc, seed):
    '''
    Pick random labels and switch their values
    '''
    np.random.seed()
    mixSize = int(len(y_train) * perc)
    #Ensure fair chance to pick any label by mixing all of the possible indices, but also ensure no duplicates
    mixIndices = np.arange(y_train.shape[0]) 
    print("Label vector length and number of labels changed: ", y_train.shape[0], mixSize)
    np.random.shuffle(mixIndices)
    for i in np.arange(mixSize):
        y_train[mixIndices[i]] = 0 if y_train[mixIndices[i]] else 1
        
def importantVocabCount(row, X_cutoff):
    sum = 0
    for i in X_cutoff:
        sum += row[i]
    return sum
  
def mixLabelsByFeat(y_train, perc, seed, vocab_arr=comb_train):
    '''
    Mixes labels based on vocabulary counts
    '''
    #Convert sparse vocab count matrix to array, and find most frequently occuring feats/perms
    X_sum = np.sum(vocab_arr, axis=0)
    X_sum_sorted = np.argsort(X_sum)

    #50th most occuring word
    cutoff = X_sum_sorted[len(X_sum)-49:len(X_sum)-50:-1] 

    #Array with each instances word count for most frequent feats/perms
    X_wc = np.apply_along_axis(importantVocabCount, axis=1, arr=vocab_arr, X_cutoff=cutoff)
    #Array with indices of the instances with the highest word count for the most frequent feats/perms
    X_wc_i = np.argsort(X_wc.ravel())

    mixSize = int(len(y_train) * perc)
    mixIndices = X_wc_i[:-(mixSize+1): -1]
    
    print("Labelsize and number of labels changed: ", y_train.shape[0], mixSize)
    print("Indices of labels changed: ", mixIndices)
    print(len(y_train))
    
    for i in np.arange(mixSize):
        y_train[mixIndices[i]] = 0 if y_train[mixIndices[i]] else 1

def mixLabelsByGradients(y_train, perc, seed):
  #Train using low level api so we don't have a preset batch size
  #Create a new model
  model=createModel()

  #Use tensorflow datasets to pass in information to tf.function
  dataset_train = tf.data.Dataset.from_tensor_slices(
    (
      perm_train,
      feat_train,
      np.array(labels_train).reshape(-1,1)
    )
  )

  dataset_test = tf.data.Dataset.from_tensor_slices(
    (
      perm_test,
      feat_test,
      np.array(labels_test).reshape(-1,1)
    )
  )

  dataset_grads = dataset_train.batch(1) #Feed in one input at a time to find its gradients but don't update weights
  dataset_batch = dataset_train.batch(32) #Train the model as normally first
  dataset_test_batch = dataset_test.batch(32) #Test set to ensure we did not screw up the model
  
  #Training and testing with tf.function
  template = 'Epoch {}, Loss: {}, Accuracy: {}'
  for epoch in range(2):
    for perm, feat, y in dataset_batch:
      train_step(perm,feat,y)
    print(template.format(epoch+1, train_loss.result(), train_accuracy.result() * 100))

  template = 'Accuracy {}'
  for perm, feat, y in dataset_test_batch:
      test_step(perm, feat, y)
  print(template.format(test_accuracy.result() * 100))
  
  #Feed one input at a time and compute gradients but do not update the model
  input_grads = []
  for perm, feat, y in dataset_grads:
    input_grad = np.sum(np.absolute(computeGrads(perm, feat, y)), axis=1)
    input_grads.append(input_grad)  
  
  #Normalize scores (optional) and arrange indices by score
  inputGrads = np.array(input_grads)
  inputGradsZ = (inputGrads - inputGrads.mean()) / inputGrads.std()
  inputsSortedByGrad = np.sort(np.sum(inputGradsZ, axis = 1))
  inputsIndicesSortedByGrad = np.argsort(np.sum(inputGradsZ, axis = 1))
  
  print('InputDifference:',inputsIndicesSortedByGrad[0]-inputsIndicesSortedByGrad[1000])
  
  #Get size of mixed labels
  mixSize = int(len(y_train) * perc)
  
  #Switch labels
  for i in range(mixSize):
    y_train[inputsIndicesSortedByGrad[-i]] = 0 if y_train[inputsIndicesSortedByGrad[-i]] else 1  
    
def mixLabelsByWeights(y_train, perc, seed):
  model=createModel()

#Train and test the model
def Test(mixP=0.0, mixStrategy=EMixStrategy.NoStrategy):
  labels_train_copy = labels_train.copy()
  
  if mixStrategy is EMixStrategy.Random:
    mixLabels(labels_train_copy, mixP, RANDOM_SEED)
  elif mixStrategy is EMixStrategy.Most_Occuring:
    mixLabelsByFeat(labels_train_copy, mixP, RANDOM_SEED)
  elif mixStrategy is EMixStrategy.Gradients:
    mixLabelsByGradients(labels_train_copy, mixP, RANDOM_SEED)
    
  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
  startTrain = timeit.default_timer()
  model.fit([perm_train, feat_train], labels_train_copy, epochs=EPOCHS, batch_size=BATCH_SIZE)
  endTrain = timeit.default_timer()
  labels_pred = model.predict([perm_test, feat_test], batch_size=BATCH_SIZE)
  endTest = timeit.default_timer()

  trainTime = endTrain - startTrain
  testTime = endTest - endTrain
  labels_pred = (labels_pred > 0.5)
  cm = confusion_matrix(labels_test, labels_pred)
  return (cm, trainTime, testTime, mixP, mixStrategy)

#Print out metrics
def calcMetrics(resTuple):
  cm = resTuple[0]
  acc = calc_accuracy(cm)
  prec = calc_precision(cm)
  rec = calc_recall(cm)
  f1 = calc_f1(prec, rec)
  print("Accuracy", acc, " Precision " ,prec, " Recall ", rec, " F1 ", f1)
  
  data = []
  data.append(dict(zip(["model_name", "neurons", "train_ratio", "input_ratio",
                        "epochs", "batch_size", "accuracy", "precision", "recall", "f1_score",
                        "train_time", "test_time", "label_mix_per", "label_mix_count"],
                        ["Dual_Large", NEURONS_PER_LAYER, TRAIN_RATIO, INPUT_RATIO, EPOCHS, BATCH_SIZE, acc, prec, rec, f1, resTuple[1], resTuple[2], resTuple[3], resTuple[3] * sampleSize])))
  save_results(data, resTuple[4])

#Test different label mixing ratios
mixPercentages = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]
model = createModel() 
initial_weights = model.get_weights() 

#Run test and reset weights afterwards
for x in mixPercentages: 
  resTuple = Test(x, EMixStrategy.Gradients) 
  calcMetrics(resTuple) 
  model.set_weights(initial_weights)

"""Finding optimal features based on gradients on trained model"""

model = createModel() 
print_weights = LambdaCallback(on_batch_end= lambda batch, logs: print(model.lay))
model.fit([perm_train, feat_train], labels_train_copy, epochs=EPOCHS, batch_size=BATCH_SIZE)
calcMetrics(resTuple)