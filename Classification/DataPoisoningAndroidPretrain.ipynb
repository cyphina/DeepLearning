{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataPoisoningAndroidPretrain",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "-Mya6im2WRIN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is an updated version to data poisoning android.  I removed the combined information since it was never used anywhere and it was eating up lots of ram.  \n",
        "\n",
        "I also started workin on implementing these techniques on datasets that already had a high degree of accuracy"
      ]
    },
    {
      "metadata": {
        "id": "FVSwWwVhvYvD",
        "colab_type": "code",
        "outputId": "4c21780b-b29a-461c-d04f-5743d8fe3395",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy as sp\n",
        "import timeit\n",
        "import datetime\n",
        "import json\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from enum import Enum\n",
        "from functools import partial\n",
        "from nltk.tokenize.regexp import regexp_tokenize\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, cross_validate\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "!pip install tensorflow-gpu==2.0.0-alpha0\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, concatenate\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==2.0.0-alpha0 in /usr/local/lib/python3.6/dist-packages (2.0.0a0)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190302,>=1.14.0a20190301 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.14.0a20190301)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.7)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.9)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.33.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.7.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.1.5)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.14.0.dev2019030115)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.7.1)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (3.7.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.16.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (0.15.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (3.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-alpha0) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-alpha0) (41.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hdlZ_-osvUy4",
        "colab_type": "code",
        "outputId": "424abb03-abb6-459e-f2f9-82f04aa024e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qDhp3ypgttVF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# PRELIMINARY WORK"
      ]
    },
    {
      "metadata": {
        "id": "WCuttgwtD7FP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CONSTANTS"
      ]
    },
    {
      "metadata": {
        "id": "Ua2E8x2ZD8LF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#File paths\n",
        "PROJECT_PATH = r\"/content/gdrive/My Drive/ML/APKAnalysis\"\n",
        "DATA_PATH = os.path.join(PROJECT_PATH, r\"Data/subsets/\")\n",
        "GOOD_PATH = os.path.join(DATA_PATH, r\"benign_badging_{}000h.txt\")\n",
        "GOOD_PATH_FULL = os.path.join(PROJECT_PATH, r\"Data/benign_badging_full_v2.txt\")\n",
        "BAD_PATH = os.path.join(DATA_PATH, r\"mal_badging_{}000h.txt\")\n",
        "BAD_PATH_FULL = os.path.join(PROJECT_PATH, r\"Data/mal_badging_full_v2.txt\")\n",
        "RESULT_PATH = os.path.join(PROJECT_PATH, \"Results\")\n",
        "\n",
        "SCORE_PATH = os.path.join(PROJECT_PATH, \"Scores\")\n",
        "SCORE_PATH_RANDOM = os.path.join(SCORE_PATH, \"RandomScores.csv\")\n",
        "SCORE_PATH_FEATOCCURANCE = os.path.join(SCORE_PATH, \"FeatOccuranceScores.csv\")\n",
        "SCORE_PATH_GRADIENTS = os.path.join(SCORE_PATH, \"GradientScores.csv\")\n",
        "SCORE_PATH_WEIGHTS = os.path.join(SCORE_PATH, \"WeightScores.csv\")\n",
        "SCORE_PATH_FURTHEST_BOUNDS = os.path.join(SCORE_PATH, \"FurthestBoundScores.csv\")\n",
        "SCORE_PATH_FURTHEST_BOUNDS_SVM = os.path.join(SCORE_PATH, \"FurthestBoundSVMScores.csv\")\n",
        "\n",
        "CHKPT_PATH = os.path.join(PROJECT_PATH, \"Checkpoints\")\n",
        "#Data params\n",
        "RANDOM_SEED = 42 #Not being used because we want to use the randomness to ensure our results are not based on a specific seed, but if you want reproducable results set this and make it used\n",
        "np.random.seed()\n",
        "SUBSET_COUNT = 4\n",
        "TRAIN_RATIO = .8\n",
        "class EMixStrategy(Enum):\n",
        "  NoStrategy = 0\n",
        "  Random = 1\n",
        "  Most_Occuring=2\n",
        "  Gradients=3\n",
        "  Weights=4\n",
        "  Furthest_Bounds=5\n",
        "  Furthest_Bounds_SVM=6\n",
        "#Model params\n",
        "NEURONS_PER_LAYER = 32\n",
        "DROPOUT_RATE = .1\n",
        "INPUT_RATIO = .125 #How large should layers in the second network in the dual newtork be compared to the first \n",
        "BATCH_SIZE=128\n",
        "EPOCHS=32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bq4g2v34F4NL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## GLOBALS"
      ]
    },
    {
      "metadata": {
        "id": "Rk87Bb1cGO7q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Store instance scores in a global variable so we don't have to recalculate them over and over\n",
        "INSTANCE_SCORES = []\n",
        "#Stores gradients when feeding every instance into the fully trained model\n",
        "INSTANCE_GRADIENTS = []\n",
        "#Saves scores into a dataframe\n",
        "SAVE_SCORES = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZYwK3wVnGACg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## File Load"
      ]
    },
    {
      "metadata": {
        "id": "ormII_CC7MoP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Create paths that we'll need for the project if they do not exist\n",
        "if not os.path.exists(RESULT_PATH):\n",
        "  os.makedirs(RESULT_PATH)  \n",
        "if not os.path.exists(SCORE_PATH):\n",
        "  os.makedirs(SCORE_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "McO37OZTvmEY",
        "colab_type": "code",
        "outputId": "07629a53-8f36-4663-c8d5-27615f6dcc03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#Load files with permissions from disk\n",
        "ben_samples = []\n",
        "mal_samples = []\n",
        "\n",
        "#Read x number of benign and malware samples\n",
        "for x in range(SUBSET_COUNT):\n",
        "  with open(GOOD_PATH.format(x+1), encoding='utf-8') as f:\n",
        "    ben_samples += f.readlines()\n",
        "  with open(BAD_PATH.format(x+1), encoding='utf-8') as f:\n",
        "    mal_samples += f.readlines()\n",
        "  \n",
        "samples = ben_samples + mal_samples\n",
        "len(samples)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "GHCeH0Aw7GM_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Add labels\n",
        "labels = np.array([])\n",
        "for x in ben_samples:\n",
        "  labels = np.append(labels, 0)\n",
        "for x in mal_samples:\n",
        "  labels = np.append(labels, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "biZrrvu19tsg",
        "colab_type": "code",
        "outputId": "e0a6cf23-ecfd-45f2-a14b-637cd095d8bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#Test out sample size\n",
        "sampleSize = len(labels)\n",
        "sampleSize"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "Ln0QxVcLDwKt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "GUlGuyok9uRG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Regex expressions formatching \n",
        "perm_pattern = \"(?:\\w|\\.)+(?:permission).(?:\\w|\\.)+\"\n",
        "feat_pattern = \"(?:\\w|\\.)+(?:hardware).(?:\\w|\\.)+\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pod0qgunibSn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Generate a matrix where the columns are the permissions and features, the rows are the instances, and the values are 1 if the permission/feature is present or not"
      ]
    },
    {
      "metadata": {
        "id": "HWol0Z5f904o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Wordcount one-hot transformer\n",
        "perm_vect = CountVectorizer(analyzer=partial(regexp_tokenize, pattern=perm_pattern))\n",
        "feat_vect = CountVectorizer(analyzer=partial(regexp_tokenize, pattern=feat_pattern))                                                                     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w_sYai_A-i3J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#If we didn't preload the vocabulary we'd call this\n",
        "#perm_input_sparse = perm_vect.fit_transform(samples)\n",
        "#feat_input_sparse = feat_vect.fit_transform(samples)\n",
        "#comb_input_sparse = comb_vect.fit_transform(samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K8r-bfQ34ljD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Preload the generated vocab over the full dataset so we don't have to call fit on the CountVectorizer"
      ]
    },
    {
      "metadata": {
        "id": "WAk5vs1k301s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Load pregenerated vocabulary from file.  Pregenerated vocab is for the entire dataset so if we are using a subset, expect sparsity\n",
        "perm_vocab = json.load(open(os.path.join(PROJECT_PATH,'perm_vocab.json')))\n",
        "feat_vocab = json.load(open(os.path.join(PROJECT_PATH,'feat_vocab.json')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pAjSUdS44rHN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Set vocabulry before transformation\n",
        "perm_vect.vocabulary_ = perm_vocab\n",
        "feat_vect.vocabulary_ = feat_vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dlixiFjdKxpf",
        "colab_type": "code",
        "outputId": "0e047bc2-e736-4ceb-885b-a0f22d79bb99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "len(feat_vect.vocabulary_.keys())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "125"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "bv-oUWnC4yeT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Generate the one-hot vectors now \n",
        "perm_input_sparse = perm_vect.transform(samples)\n",
        "feat_input_sparse = feat_vect.transform(samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZMCze6Zt-oFZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#perm_inputs = perm_input_sparse\n",
        "#feat_inputs = feat_input_sparse\n",
        "\n",
        "#To numpy array for easier use (not necessary unless using tensorflow eager execution)\n",
        "perm_inputs = perm_input_sparse.toarray()\n",
        "feat_inputs = feat_input_sparse.toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UCVLSwtRi-KX",
        "colab_type": "code",
        "outputId": "33c5d2aa-7bc1-4b47-99c6-5c2b72833846",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "cell_type": "code",
      "source": [
        "print(feat_inputs.shape, \"\\n\", feat_inputs) #Shows us for each instances what features it has "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8000, 125) \n",
            " [[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1egGL3jjApGD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "perm_vocab_width = perm_inputs.shape[1]\n",
        "feat_vocab_width = feat_inputs.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "93UtdiEPjeB1",
        "colab_type": "code",
        "outputId": "26bfdd22-4cb2-425c-824b-fe968596f571",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "perm_vocab_width, feat_vocab_width"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17121, 125)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "3RvAXg3_B9oA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sss = StratifiedShuffleSplit(n_splits=1, random_state=0, test_size=1-TRAIN_RATIO)\n",
        "for train_index, test_index in sss.split(perm_inputs, labels):\n",
        "  perm_train, perm_test = perm_inputs[train_index], perm_inputs[test_index]\n",
        "  feat_train, feat_test = feat_inputs[train_index], feat_inputs[test_index]\n",
        "  \n",
        "  perm_train_sparse, perm_test_sparse = perm_input_sparse[train_index], perm_input_sparse[test_index]\n",
        "  feat_train_sparse, feat_test_sparse = feat_input_sparse[train_index], feat_input_sparse[test_index]\n",
        "  \n",
        "  labels_train, labels_test = labels[train_index], labels[test_index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M484QyxsINqa",
        "colab_type": "code",
        "outputId": "c01ce6cb-b864-437a-8ad7-64045d1fc78d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "perm_train.shape, \"\\n\", feat_train.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6400, 17121), '\\n', (6400, 125))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "gnCrvSFSIUsJ",
        "colab_type": "code",
        "outputId": "729c4dd5-76d8-43cb-a34f-9224c5644819",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "labels_train"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 1., ..., 1., 1., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "bmgzynzJ1BGU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Flipping\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Here are thing related to the poisoning techniques implemented"
      ]
    },
    {
      "metadata": {
        "id": "G4ycAj5h_Gqu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model Creation"
      ]
    },
    {
      "metadata": {
        "id": "3flZA81RIWk7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Model creation\n",
        "def createModel():\n",
        "  perm_input_layer = Input(shape=(perm_vocab_width,), name='permissions_input')\n",
        "  h1_perm = Dense(NEURONS_PER_LAYER, activation='relu')(perm_input_layer)\n",
        "  h1_perm = Dropout(DROPOUT_RATE)(h1_perm)\n",
        "  h2_perm = Dense(NEURONS_PER_LAYER, activation='relu')(h1_perm)\n",
        "  feat_input_layer = Input(shape=(feat_vocab_width,), name='features_input')\n",
        "  h1_feat = Dense(int(NEURONS_PER_LAYER*INPUT_RATIO), activation='relu')(feat_input_layer)\n",
        "  #Combine last layer of first network (handling permissions)with first layer of the second network (handling features)\n",
        "  h1_comb = concatenate([h2_perm, h1_feat])\n",
        "  h2_comb = Dense(int((NEURONS_PER_LAYER+(NEURONS_PER_LAYER*INPUT_RATIO))/2), activation='relu')(h1_comb)\n",
        "  h2_comb = Dropout(DROPOUT_RATE)(h2_comb)\n",
        "  h3_comb = Dense(int((NEURONS_PER_LAYER+(NEURONS_PER_LAYER*INPUT_RATIO))/2), activation='relu')(h2_comb)\n",
        "  output = Dense(1, activation='sigmoid', name=\"output\")(h3_comb)\n",
        "  model = Model(inputs=[perm_input_layer, feat_input_layer], outputs=output)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zG_J-J1t_KyC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Helper and Scoring Functions"
      ]
    },
    {
      "metadata": {
        "id": "7ivIDEzfeKs_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def saveScores(data, score_path):\n",
        "  '''Saves scores of for all instances using various scoring techniques'''\n",
        "  print(\"Saving scores at: \", score_path)\n",
        "  df = pd.DataFrame(data)\n",
        "  df.to_csv(score_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ElVw20j3raun",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Test but keep track of gradients\n",
        "#Theory: We want to keep track of how much each feature contributes to the final model\n",
        "#One proposed way is to average the gradients of the trained model for each input\n",
        "\n",
        "loss_object = tf.keras.losses.BinaryCrossentropy()\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer()\n",
        "  \n",
        "@tf.function\n",
        "def computeGrads(perms, feats, labels):\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model([perms, feats])\n",
        "    loss = loss_object(labels, predictions)\n",
        "\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  input_gradient = gradients[0]\n",
        "  return input_gradient"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sUhtt0a-bkfI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_accuracy = tf.keras.metrics.BinaryAccuracy(name='train_accuracy')\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "\n",
        "@tf.function\n",
        "def train_step(perms, feats, labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model([perms, feats])\n",
        "    loss = loss_object(labels, predictions)\n",
        "\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients,model.trainable_variables))\n",
        "   \n",
        "  train_loss(loss)\n",
        "  train_accuracy(labels, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sT8d-8UJT9ZO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_accuracy = tf.keras.metrics.BinaryAccuracy(name='test_accuracy')\n",
        "\n",
        "@tf.function\n",
        "def test_step(perms, feats, labels):\n",
        "  predictions = model([perms, feats])\n",
        "  accuracy = test_accuracy(labels, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7OFfUQw8_EMZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Metric functions\n",
        "def calc_accuracy(cm):\n",
        "    TP = float(cm[1][1])\n",
        "    TN = float(cm[0][0])\n",
        "    n_samples = cm.sum()\n",
        "    return (TP+TN)/n_samples\n",
        "\n",
        "def calc_precision(cm):\n",
        "    TP = float(cm[1][1])\n",
        "    FP = float(cm[0][1])\n",
        "    return TP/(TP+FP)\n",
        "\n",
        "def calc_recall(cm):\n",
        "    TP = float(cm[1][1])\n",
        "    FN = float(cm[1][0])\n",
        "    return TP/(FN+TP)\n",
        "\n",
        "def calc_f1(precision, recall):\n",
        "    return 2*((precision*recall)/(precision+recall))\n",
        "  \n",
        "def save_results(data,mixStrategy):\n",
        "  d = datetime.datetime.today()\n",
        "  month = str( '%02d' % d.month)\n",
        "  day = str('%02d' % d.day)\n",
        "  hour = str('%02d' % d.hour)\n",
        "  year = str('%02d' % d.year)\n",
        "  min = str('%02d' % d.minute)\n",
        "\n",
        "  df = pd.DataFrame(data)\n",
        "\n",
        "  modelLabel = \"mixP\" + str(data[0][\"label_mix_per\"]) + \"-size\" + str(sampleSize) + \"-strat\" +  str(mixStrategy) + \".csv\"\n",
        "  modelPath = os.path.join(RESULT_PATH, modelLabel)\n",
        "  print(\"Saving Results at \" + modelPath + \"!\")\n",
        "  \n",
        "  isNewFile = not os.path.exists(modelPath)\n",
        "  with open(modelPath, \"a+\") as f:\n",
        "      df.to_csv(f, mode='a', header=isNewFile, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lafivwJTKL0b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Mix Functions"
      ]
    },
    {
      "metadata": {
        "id": "TTm7RMw2KSpm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def GetMixSize(y_train, perc):\n",
        "    return int(len(y_train) * perc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kUqCVgrTKTQ-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Data poisoning label mixing formulas\n",
        "def mixLabels(y_train, perc, seed):\n",
        "    '''\n",
        "    Pick random labels and switch their values\n",
        "    '''\n",
        "    mixSize = GetMixSize(y_train, perc)\n",
        "    #Ensure fair chance to pick any label by mixing all of the possible indices, but also ensure no duplicates\n",
        "    mixIndices = np.arange(y_train.shape[0]) \n",
        "    print(\"Label vector length and number of labels changed: \", y_train.shape[0], mixSize)\n",
        "    \n",
        "    if SAVE_SCORES:\n",
        "       data = {'RandomOrder':mixIndices}\n",
        "       saveScores(data, SCORE_PATH_RANDOM)\n",
        "              \n",
        "    np.random.shuffle(mixIndices)\n",
        "    for i in np.arange(mixSize):\n",
        "        y_train[mixIndices[-i-1]] = 0 if y_train[mixIndices[-i-1]] else 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cKjCeq1bKbTc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def findImportantVocab(vocab_arr, cutoff=50):\n",
        "  '''Finds what words are the most occuring amongst given a vocabulary matrix (each row is the word count for an instance)'''\n",
        "  vocab_arr = feat_train\n",
        "  X_sum = np.sum(vocab_arr, axis=0)\n",
        "  X_sum_sorted = np.argsort(X_sum)\n",
        "    \n",
        "  #Now that we have the INDICES of the words sorted by occurance, we can choose the number of most common words we want\n",
        "  vocab_cutoff = X_sum_sorted[len(X_sum):len(X_sum)-cutoff:-1] \n",
        "  return vocab_cutoff\n",
        "  \n",
        "def importantVocabCount(row, X_important):\n",
        "  '''Count how many important features an instance has'''\n",
        "  sum = 0\n",
        "  for i in X_important:\n",
        "    sum += row[i]\n",
        "  return sum\n",
        "\n",
        "def mixLabelsByFeat(y_train, perc, seed):\n",
        "  '''\n",
        "  Mixes labels based on vocabulary counts\n",
        "  '''\n",
        "  FEAT_SCALING = 0.8 # Since there are less features, we'll decrease its impact in the scoring function\n",
        "  \n",
        "  perm_vocab_important = findImportantVocab(perm_train)\n",
        "  perm_wc = np.apply_along_axis(importantVocabCount, axis=1, arr=perm_train, X_important=perm_vocab_important)\n",
        "  \n",
        "  feat_vocab_important = findImportantVocab(feat_train)\n",
        "  feat_wc = np.apply_along_axis(importantVocabCount, axis=1, arr=feat_train, X_important=feat_vocab_important) #Array with each instances word count for most frequent feats \n",
        "  feat_wc = feat_wc * 0.8\n",
        "    \n",
        "  X_wc = np.add(feat_wc * FEAT_SCALING, perm_wc) \n",
        "  \n",
        "  if SAVE_SCORES:\n",
        "    data = {'FeatCountScores':X_wc}\n",
        "    saveScores(data, SCORE_PATH_FEATOCCURANCE)\n",
        "              \n",
        "  mixIndices = np.argsort(X_wc.ravel()) #Array with indices of the instances with the highest word count for the most frequent feats/perms\n",
        "  \n",
        "  mixSize = GetMixSize(y_train, perc)\n",
        "\n",
        "  print(\"Labelsize and number of labels changed: \", y_train.shape[0], mixSize)\n",
        "  print(\"Indices of labels changed: \", mixIndices)\n",
        "  print(len(y_train))\n",
        "\n",
        "  for i in np.arange(mixSize):\n",
        "      y_train[mixIndices[-i-1]] = 0 if y_train[mixIndices[-i-1]] else 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RJ9Sl1GPKfzU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def mixLabelsByGradients(y_train, perc, seed):\n",
        "  #Train using low level api so we don't have a preset batch size\n",
        "  #Create a new model\n",
        "  global INSTANCE_GRADIENTS\n",
        "  \n",
        "  if not INSTANCE_GRADIENTS:  \n",
        "    model=createModel()\n",
        "\n",
        "    #Use tensorflow datasets to pass in information to tf.function\n",
        "    dataset_train = tf.data.Dataset.from_tensor_slices(\n",
        "      (\n",
        "        perm_train,\n",
        "        feat_train,\n",
        "        np.array(labels_train).reshape(-1,1)\n",
        "      )\n",
        "    )\n",
        "\n",
        "    dataset_test = tf.data.Dataset.from_tensor_slices(\n",
        "      (\n",
        "        perm_test,\n",
        "        feat_test,\n",
        "        np.array(labels_test).reshape(-1,1)\n",
        "      )\n",
        "    )\n",
        "\n",
        "    dataset_grads = dataset_train.batch(1) #Feed in one input at a time to find its gradients but don't update weights\n",
        "    checkpoint = tf.train.Checkpoint(model=model)\n",
        "    checkpoint.restore(os.path.join(CHKPT_PATH, \"FinalResult-1\"))\n",
        "\n",
        "    #Feed one input at a time and compute gradients but do not update the model\n",
        "    input_grads = []\n",
        "    for perm, feat, y in dataset_grads:\n",
        "      input_grad = np.sum(np.absolute(computeGrads(perm, feat, y)), axis=1)\n",
        "      input_grads.append(input_grad)  \n",
        "\n",
        "    if SAVE_SCORES:\n",
        "      data = {'GradientScores':input_grads}\n",
        "      saveScores(data, SCORE_PATH_GRADIENTS)\n",
        "              \n",
        "    #Normalize scores (optional) and arrange indices by score\n",
        "    inputGrads = np.array(input_grads)\n",
        "    inputGradsZ = (inputGrads - inputGrads.mean()) / inputGrads.std()\n",
        "    inputsSortedByGrad = np.sort(np.sum(inputGradsZ, axis = 1))\n",
        "    #Should be the same between runs unless model changes\n",
        "    inputsIndicesSortedByGrad = np.argsort(np.sum(inputGradsZ, axis = 1)) \n",
        "  \n",
        "  #Get size of mixed labels\n",
        "  mixSize = GetMixSize(y_train, perc)\n",
        "  \n",
        "  #Switch labels\n",
        "  for i in range(mixSize):\n",
        "    y_train[inputsIndicesSortedByGrad[-i-1]] = 0 if y_train[inputsIndicesSortedByGrad[-i-1]] else 1  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_UWZzA6OKoDp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def calculateInstanceScores(instanceScores):\n",
        "  '''Pass an array to hold the scores of all the instances based off the weights'''\n",
        "  #Optimal weights from running a normal case is saved in this checkpoint already.  If we lose the checkpoint then just save another one by running the model\n",
        "  #without any mixups\n",
        "  model=createModel()\n",
        "  checkpoint = tf.train.Checkpoint(model=model)\n",
        "  checkpoint.restore(os.path.join(CHKPT_PATH, \"FinalResult-1\"))\n",
        "  #Get weights associated with each feature in input layer (exclude bias weights)\n",
        "  \n",
        "  permWeights = np.mean(np.abs(model.layers[1].get_weights()[0]), axis=1)\n",
        "  hardwarePermWeights = np.mean(np.abs(model.layers[5].get_weights()[0]), axis=1)\n",
        "  \n",
        "  for x in perm_train:\n",
        "    score = 0\n",
        "    for i, x_feat in enumerate(x):\n",
        "      if x_feat == 1:\n",
        "        score = score + permWeights[i] \n",
        "    instanceScores.append(score)\n",
        "  \n",
        "  for i, x in enumerate(feat_train):\n",
        "    score = 0\n",
        "    for i, x_feat in enumerate(x):\n",
        "      if x_feat == 1:\n",
        "        score = score + hardwarePermWeights[i] \n",
        "    instanceScores[i] += score \n",
        "  \n",
        "  if SAVE_SCORES:\n",
        "    if len(hardwarePermWeights) < len(permWeights):\n",
        "      hardwarePermWeightsPad = hardwarePermWeights.resize(len(permWeights))\n",
        "    data = {'PermWeights': permWeights, 'HardwarePermWeights': hardwarePermWeights}\n",
        "    saveScores(data, SCORE_PATH_WEIGHTS)\n",
        "\n",
        "def mixLabelsByWeights(y_train, instanceScores, perc, seed):\n",
        "  #Not the greatest check but it prevents repeatedly calculating the scores for all instances\n",
        "  if not INSTANCE_SCORES:\n",
        "    calculateInstanceScores(INSTANCE_SCORES)\n",
        "    \n",
        "  instIndSortedByScore = np.argsort(instanceScores)  \n",
        "  mixSize = GetMixSize(y_train, perc)\n",
        "  \n",
        "  for i in range(mixSize):\n",
        "    y_train[instIndSortedByScore[-i-1]] = 0 if y_train[instIndSortedByScore[-i-1]] else 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WO6HlRAY0F_q",
        "colab_type": "code",
        "outputId": "cc97e875-8e2c-4969-905f-f7f1c4eb87c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "model = createModel()\n",
        "np.mean(np.abs(model.layers[1].get_weights()[0]), axis=1).shape"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17121,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "metadata": {
        "id": "ZMpdd6YHbwRx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def mixLabelsByProba(y_train, perc, seed):\n",
        "  '''Mix labels that have large probabilities of being a certain class.  Akin to furthest-first attacks'''  \n",
        "  model=createModel()\n",
        "  checkpoint = tf.train.Checkpoint(model=model)\n",
        "  checkpoint.restore(os.path.join(CHKPT_PATH, \"FinalResult-1\"))\n",
        "  \n",
        "  #This time predict on training set\n",
        "  labels_pred = model.predict([perm_train, feat_train], batch_size=BATCH_SIZE)\n",
        "  \n",
        "  flat_labels = labels_pred.flatten()\n",
        "  \n",
        "  if SAVE_SCORES:\n",
        "    data = {'ProbaScores':flat_labels}\n",
        "    saveScores(data, SCORE_PATH_FURTHEST_BOUNDS)\n",
        "    \n",
        "  flat_label_indices = np.argsort(np.abs(flat_labels - np.full(flat_labels.shape, 0.5)))\n",
        "\n",
        "  mixSize = GetMixSize(y_train, perc)\n",
        "  \n",
        "  for i in range(mixSize):\n",
        "    print(flat_label_indices[-i-1])\n",
        "    y_train[flat_label_indices[-i-1]] = 0 if y_train[flat_label_indices[-i-1]] else 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TsKu-n3TzRla",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def mixLabelsBySVM(y_train, perc, seed):\n",
        "  '''Mix labels according to data poisoning techniques that exist for an SVM clasifier, and see how they perform with the DNN'''\n",
        "  #Should load a SVM with saved model parameters\n",
        "  svm_clf = SVC(C=100, gamma=\"scale\")\n",
        "  comb_inst = sp.sparse.hstack([perm_train_sparse, feat_train_sparse]) #combine feats and perms since we don't have dual input for this model\n",
        "  svm_clf.fit(comb_inst, labels_train)\n",
        "  #y_pred = svm_clf.predict(sp.sparse.hstack([perm_test,feat_test]))\n",
        "  y_decision = np.abs(svm_clf.decision_function(comb_inst).reshape(perm_train.shape[0]))\n",
        "  \n",
        "  if SAVE_SCORES:\n",
        "    data = {'SVMProbaScores':y_decision}\n",
        "    saveScores(data, SCORE_PATH_FURTHEST_BOUNDS_SVM)\n",
        "              \n",
        "  label_indices = np.argsort(y_decision)\n",
        "  mixSize = GetMixSize(y_train, perc)\n",
        "  \n",
        "  for i in range(mixSize):\n",
        "    y_train[label_indices[-i-1]] = 0 if y_train[label_indices[-i-1]] else 1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ic8I6lhq1KPM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Testing and Scoring\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Here is where the code for testing the models using the different label flipping techniques and computing metrics occurs"
      ]
    },
    {
      "metadata": {
        "id": "-eW-fFNef6oG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Train and test the model\n",
        "def Test(mixP=0.0, mixStrategy=EMixStrategy.NoStrategy):\n",
        "  '''Creates a model with a certain amount of labels flippped as according to a strategy.  \n",
        "  Uses keras instead of writing out tensorflow function since this is how it written originally'''\n",
        "  labels_train_copy = labels_train.copy()\n",
        "  \n",
        "  checkpointPath = os.path.join(CHKPT_PATH, str(mixStrategy))  \n",
        "  checkpointName = os.path.join(checkpointPath, \"CheckpointMixPer\" + str(mixP))\n",
        "  \n",
        "  if not os.path.exists(checkpointPath):\n",
        "    os.makedirs(checkpointPath)\n",
        "    \n",
        "  print(\"Saving checkpoint at \", checkpointPath)\n",
        "  checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpointName, save_weights_only=True)\n",
        "                                \n",
        "  if mixStrategy is EMixStrategy.Random:\n",
        "    mixLabels(labels_train_copy, mixP, RANDOM_SEED)\n",
        "  elif mixStrategy is EMixStrategy.Most_Occuring:\n",
        "    mixLabelsByFeat(labels_train_copy, mixP, RANDOM_SEED)\n",
        "  elif mixStrategy is EMixStrategy.Gradients:\n",
        "    mixLabelsByGradients(labels_train_copy, mixP, RANDOM_SEED)\n",
        "  elif mixStrategy is EMixStrategy.Weights:\n",
        "    mixLabelsByWeights(labels_train_copy, INSTANCE_SCORES, mixP, RANDOM_SEED)\n",
        "  elif mixStrategy is EMixStrategy.Furthest_Bounds:\n",
        "    mixLabelsByProba(labels_train_copy, mixP, RANDOM_SEED)\n",
        "  elif mixStrategy is EMixStrategy.Furthest_Bounds_SVM:\n",
        "    mixLabelsBySVM(labels_train_copy, mixP, RANDOM_SEED)\n",
        "    \n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  startTrain = timeit.default_timer()\n",
        "  model.fit([perm_train, feat_train], labels_train_copy, epochs=EPOCHS, batch_size=BATCH_SIZE, callbacks=[checkpoint])\n",
        "  endTrain = timeit.default_timer()\n",
        "  labels_pred = model.predict([perm_test, feat_test], batch_size=BATCH_SIZE)\n",
        "  endTest = timeit.default_timer()\n",
        "\n",
        "  trainTime = endTrain - startTrain\n",
        "  testTime = endTest - endTrain\n",
        "  labels_pred = (labels_pred > 0.5)\n",
        "  cm = confusion_matrix(labels_test, labels_pred)\n",
        "  return (cm, trainTime, testTime, mixP, mixStrategy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7rYe-csPrHQZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Print out metrics\n",
        "def calcMetrics(resTuple):\n",
        "  cm = resTuple[0]\n",
        "  acc = calc_accuracy(cm)\n",
        "  prec = calc_precision(cm)\n",
        "  rec = calc_recall(cm)\n",
        "  f1 = calc_f1(prec, rec)\n",
        "  print(\"Accuracy\", acc, \" Precision \" ,prec, \" Recall \", rec, \" F1 \", f1)\n",
        "  \n",
        "  data = []\n",
        "  data.append(dict(zip([\"model_name\", \"neurons\", \"train_ratio\", \"input_ratio\",\n",
        "                        \"epochs\", \"batch_size\", \"accuracy\", \"precision\", \"recall\", \"f1_score\",\n",
        "                        \"train_time\", \"test_time\", \"label_mix_per\", \"label_mix_count\"],\n",
        "                        [\"Dual_Large\", NEURONS_PER_LAYER, TRAIN_RATIO, INPUT_RATIO, EPOCHS, BATCH_SIZE, acc, prec, rec, f1, resTuple[1], resTuple[2], resTuple[3], resTuple[3] * sampleSize])))\n",
        "  save_results(data, resTuple[4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pz8pUvctAtKA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here is some code to save the optimal weights however we do not have to run this all the time"
      ]
    },
    {
      "metadata": {
        "id": "b1BNYk9-iP99",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Test Driver"
      ]
    },
    {
      "metadata": {
        "id": "LKgQ6xH1K09j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16767
        },
        "outputId": "15b2f155-8bf8-45ad-9b68-ba585583df91"
      },
      "cell_type": "code",
      "source": [
        "#Test different label mixing ratios\n",
        "mixPercentages = [0.1] #[0.0, 0.1,0.2,0.3,0.4,0.5, 0.6,0.7,0.8,0.9,1.0] \n",
        "strategies = [EMixStrategy.Gradients, EMixStrategy.Weights, EMixStrategy.Furthest_Bounds, EMixStrategy.Furthest_Bounds_SVM]\n",
        "model = createModel() \n",
        "initial_weights = model.get_weights() \n",
        "\n",
        "#Run test and reset weights afterwards\n",
        "for s in strategies:\n",
        "  for x in mixPercentages: \n",
        "    for _ in range(1):\n",
        "      resTuple = Test(x, s) \n",
        "      calcMetrics(resTuple) \n",
        "      model.set_weights(initial_weights)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving checkpoint at  /content/gdrive/My Drive/ML/APKAnalysis/Checkpoints/EMixStrategy.Gradients\n",
            "Saving scores at:  /content/gdrive/My Drive/ML/APKAnalysis/Scores/GradientScores\n",
            "Epoch 1/32\n",
            "6400/6400 [==============================] - 1s 182us/sample - loss: 0.6220 - accuracy: 0.7623\n",
            "Epoch 2/32\n",
            "6400/6400 [==============================] - 1s 147us/sample - loss: 0.3944 - accuracy: 0.8442\n",
            "Epoch 3/32\n",
            "6400/6400 [==============================] - 1s 149us/sample - loss: 0.3202 - accuracy: 0.8702\n",
            "Epoch 4/32\n",
            "6400/6400 [==============================] - 1s 148us/sample - loss: 0.2981 - accuracy: 0.8847\n",
            "Epoch 5/32\n",
            "6400/6400 [==============================] - 1s 146us/sample - loss: 0.2776 - accuracy: 0.8917\n",
            "Epoch 6/32\n",
            "6400/6400 [==============================] - 1s 142us/sample - loss: 0.2578 - accuracy: 0.9006\n",
            "Epoch 7/32\n",
            "6400/6400 [==============================] - 1s 138us/sample - loss: 0.2441 - accuracy: 0.9058\n",
            "Epoch 8/32\n",
            "6400/6400 [==============================] - 1s 142us/sample - loss: 0.2276 - accuracy: 0.9150\n",
            "Epoch 9/32\n",
            "6400/6400 [==============================] - 1s 140us/sample - loss: 0.2191 - accuracy: 0.9195\n",
            "Epoch 10/32\n",
            "6400/6400 [==============================] - 1s 182us/sample - loss: 0.2056 - accuracy: 0.9214\n",
            "Epoch 11/32\n",
            "6400/6400 [==============================] - 1s 143us/sample - loss: 0.1998 - accuracy: 0.9283\n",
            "Epoch 12/32\n",
            "6400/6400 [==============================] - 1s 143us/sample - loss: 0.1902 - accuracy: 0.9308\n",
            "Epoch 13/32\n",
            "6400/6400 [==============================] - 1s 143us/sample - loss: 0.1879 - accuracy: 0.9303\n",
            "Epoch 14/32\n",
            "6400/6400 [==============================] - 1s 141us/sample - loss: 0.1795 - accuracy: 0.9344\n",
            "Epoch 15/32\n",
            "6400/6400 [==============================] - 1s 141us/sample - loss: 0.1746 - accuracy: 0.9380\n",
            "Epoch 16/32\n",
            "6400/6400 [==============================] - 1s 139us/sample - loss: 0.1703 - accuracy: 0.9353\n",
            "Epoch 17/32\n",
            "6400/6400 [==============================] - 1s 139us/sample - loss: 0.1625 - accuracy: 0.9394\n",
            "Epoch 18/32\n",
            "6400/6400 [==============================] - 1s 141us/sample - loss: 0.1622 - accuracy: 0.9400\n",
            "Epoch 19/32\n",
            "6400/6400 [==============================] - 1s 141us/sample - loss: 0.1627 - accuracy: 0.9395\n",
            "Epoch 20/32\n",
            "6400/6400 [==============================] - 1s 142us/sample - loss: 0.1596 - accuracy: 0.9420\n",
            "Epoch 21/32\n",
            "6400/6400 [==============================] - 1s 145us/sample - loss: 0.1603 - accuracy: 0.9398\n",
            "Epoch 22/32\n",
            "6400/6400 [==============================] - 1s 141us/sample - loss: 0.1573 - accuracy: 0.9405\n",
            "Epoch 23/32\n",
            "6400/6400 [==============================] - 1s 138us/sample - loss: 0.1498 - accuracy: 0.9428\n",
            "Epoch 24/32\n",
            "6400/6400 [==============================] - 1s 142us/sample - loss: 0.1485 - accuracy: 0.9464\n",
            "Epoch 25/32\n",
            "6400/6400 [==============================] - 1s 150us/sample - loss: 0.1455 - accuracy: 0.9473\n",
            "Epoch 26/32\n",
            "6400/6400 [==============================] - 1s 143us/sample - loss: 0.1488 - accuracy: 0.9444\n",
            "Epoch 27/32\n",
            "6400/6400 [==============================] - 1s 142us/sample - loss: 0.1455 - accuracy: 0.9486\n",
            "Epoch 28/32\n",
            "6400/6400 [==============================] - 1s 140us/sample - loss: 0.1427 - accuracy: 0.9486\n",
            "Epoch 29/32\n",
            "6400/6400 [==============================] - 1s 139us/sample - loss: 0.1349 - accuracy: 0.9502\n",
            "Epoch 30/32\n",
            "6400/6400 [==============================] - 1s 138us/sample - loss: 0.1378 - accuracy: 0.9502\n",
            "Epoch 31/32\n",
            "6400/6400 [==============================] - 1s 141us/sample - loss: 0.1376 - accuracy: 0.9477\n",
            "Epoch 32/32\n",
            "6400/6400 [==============================] - 1s 142us/sample - loss: 0.1363 - accuracy: 0.9477\n",
            "Accuracy 0.850625  Precision  0.8956276445698167  Recall  0.79375  F1  0.8416169648774022\n",
            "Saving Results at /content/gdrive/My Drive/ML/APKAnalysis/Results/mixP0.1-size8000-stratEMixStrategy.Gradients.csv!\n",
            "Saving checkpoint at  /content/gdrive/My Drive/ML/APKAnalysis/Checkpoints/EMixStrategy.Weights\n",
            "Saving scores at:  /content/gdrive/My Drive/ML/APKAnalysis/Scores/WeightScores\n",
            "Epoch 1/32\n",
            "6400/6400 [==============================] - 1s 171us/sample - loss: 0.6266 - accuracy: 0.7250\n",
            "Epoch 2/32\n",
            "6400/6400 [==============================] - 1s 142us/sample - loss: 0.3979 - accuracy: 0.8444\n",
            "Epoch 3/32\n",
            "6400/6400 [==============================] - 1s 139us/sample - loss: 0.3066 - accuracy: 0.8755\n",
            "Epoch 4/32\n",
            "6400/6400 [==============================] - 1s 142us/sample - loss: 0.2759 - accuracy: 0.8897\n",
            "Epoch 5/32\n",
            "6400/6400 [==============================] - 1s 140us/sample - loss: 0.2549 - accuracy: 0.8986\n",
            "Epoch 6/32\n",
            "6400/6400 [==============================] - 1s 144us/sample - loss: 0.2362 - accuracy: 0.9083\n",
            "Epoch 7/32\n",
            "6400/6400 [==============================] - 1s 147us/sample - loss: 0.2222 - accuracy: 0.9147\n",
            "Epoch 8/32\n",
            "6400/6400 [==============================] - 1s 142us/sample - loss: 0.2104 - accuracy: 0.9189\n",
            "Epoch 9/32\n",
            "6400/6400 [==============================] - 1s 142us/sample - loss: 0.1995 - accuracy: 0.9244\n",
            "Epoch 10/32\n",
            "6400/6400 [==============================] - 1s 143us/sample - loss: 0.1895 - accuracy: 0.9294\n",
            "Epoch 11/32\n",
            "6400/6400 [==============================] - 1s 143us/sample - loss: 0.1833 - accuracy: 0.9317\n",
            "Epoch 12/32\n",
            "6400/6400 [==============================] - 1s 143us/sample - loss: 0.1798 - accuracy: 0.9327\n",
            "Epoch 13/32\n",
            "6400/6400 [==============================] - 1s 151us/sample - loss: 0.1708 - accuracy: 0.9355\n",
            "Epoch 14/32\n",
            "6400/6400 [==============================] - 1s 149us/sample - loss: 0.1669 - accuracy: 0.9392\n",
            "Epoch 15/32\n",
            "6400/6400 [==============================] - 1s 150us/sample - loss: 0.1619 - accuracy: 0.9406\n",
            "Epoch 16/32\n",
            "6400/6400 [==============================] - 1s 149us/sample - loss: 0.1575 - accuracy: 0.9434\n",
            "Epoch 17/32\n",
            "6400/6400 [==============================] - 1s 150us/sample - loss: 0.1547 - accuracy: 0.9413\n",
            "Epoch 18/32\n",
            "6400/6400 [==============================] - 1s 153us/sample - loss: 0.1537 - accuracy: 0.9448\n",
            "Epoch 19/32\n",
            "6400/6400 [==============================] - 1s 149us/sample - loss: 0.1492 - accuracy: 0.9463\n",
            "Epoch 20/32\n",
            "6400/6400 [==============================] - 1s 150us/sample - loss: 0.1478 - accuracy: 0.9445\n",
            "Epoch 21/32\n",
            "6400/6400 [==============================] - 1s 151us/sample - loss: 0.1449 - accuracy: 0.9473\n",
            "Epoch 22/32\n",
            "6400/6400 [==============================] - 1s 156us/sample - loss: 0.1411 - accuracy: 0.9466\n",
            "Epoch 23/32\n",
            "6400/6400 [==============================] - 1s 146us/sample - loss: 0.1391 - accuracy: 0.9491\n",
            "Epoch 24/32\n",
            "6400/6400 [==============================] - 1s 140us/sample - loss: 0.1404 - accuracy: 0.9478\n",
            "Epoch 25/32\n",
            "6400/6400 [==============================] - 1s 139us/sample - loss: 0.1391 - accuracy: 0.9458\n",
            "Epoch 26/32\n",
            "6400/6400 [==============================] - 1s 145us/sample - loss: 0.1337 - accuracy: 0.9494\n",
            "Epoch 27/32\n",
            "6400/6400 [==============================] - 1s 142us/sample - loss: 0.1311 - accuracy: 0.9528\n",
            "Epoch 28/32\n",
            "6400/6400 [==============================] - 1s 140us/sample - loss: 0.1333 - accuracy: 0.9522\n",
            "Epoch 29/32\n",
            "6400/6400 [==============================] - 1s 148us/sample - loss: 0.1315 - accuracy: 0.9516\n",
            "Epoch 30/32\n",
            "6400/6400 [==============================] - 1s 144us/sample - loss: 0.1320 - accuracy: 0.9506\n",
            "Epoch 31/32\n",
            "6400/6400 [==============================] - 1s 142us/sample - loss: 0.1308 - accuracy: 0.9503\n",
            "Epoch 32/32\n",
            "6400/6400 [==============================] - 1s 145us/sample - loss: 0.1269 - accuracy: 0.9520\n",
            "Accuracy 0.839375  Precision  0.8895265423242468  Recall  0.775  F1  0.8283233132932533\n",
            "Saving Results at /content/gdrive/My Drive/ML/APKAnalysis/Results/mixP0.1-size8000-stratEMixStrategy.Weights.csv!\n",
            "Saving checkpoint at  /content/gdrive/My Drive/ML/APKAnalysis/Checkpoints/EMixStrategy.Furthest_Bounds\n",
            "Saving scores at:  /content/gdrive/My Drive/ML/APKAnalysis/Scores/FurthestBoundScores\n",
            "1257\n",
            "3205\n",
            "3233\n",
            "3231\n",
            "569\n",
            "568\n",
            "5482\n",
            "3227\n",
            "1860\n",
            "3225\n",
            "565\n",
            "5489\n",
            "3224\n",
            "4712\n",
            "3220\n",
            "5493\n",
            "1011\n",
            "5495\n",
            "1876\n",
            "4722\n",
            "4723\n",
            "5472\n",
            "577\n",
            "582\n",
            "1828\n",
            "1829\n",
            "579\n",
            "5456\n",
            "3928\n",
            "3250\n",
            "3244\n",
            "3936\n",
            "4735\n",
            "1851\n",
            "1470\n",
            "1852\n",
            "3934\n",
            "574\n",
            "3239\n",
            "3208\n",
            "3197\n",
            "4701\n",
            "5500\n",
            "5522\n",
            "543\n",
            "5524\n",
            "3163\n",
            "3159\n",
            "3157\n",
            "5529\n",
            "5530\n",
            "1909\n",
            "3152\n",
            "541\n",
            "1453\n",
            "3150\n",
            "5536\n",
            "3149\n",
            "536\n",
            "5540\n",
            "3165\n",
            "3949\n",
            "5519\n",
            "553\n",
            "560\n",
            "1888\n",
            "3187\n",
            "5504\n",
            "1892\n",
            "3181\n",
            "554\n",
            "3173\n",
            "3946\n",
            "1899\n",
            "548\n",
            "5513\n",
            "5514\n",
            "5515\n",
            "1902\n",
            "1906\n",
            "1474\n",
            "3926\n",
            "996\n",
            "995\n",
            "3330\n",
            "3328\n",
            "5385\n",
            "626\n",
            "3327\n",
            "3890\n",
            "3892\n",
            "624\n",
            "3322\n",
            "3321\n",
            "980\n",
            "3893\n",
            "3314\n",
            "1808\n",
            "5397\n",
            "5398\n",
            "1810\n",
            "1806\n",
            "627\n",
            "977\n",
            "5364\n",
            "5357\n",
            "4317\n",
            "1798\n",
            "5360\n",
            "975\n",
            "3883\n",
            "3340\n",
            "3886\n",
            "5374\n",
            "3338\n",
            "4782\n",
            "3335\n",
            "635\n",
            "633\n",
            "1803\n",
            "5373\n",
            "614\n",
            "1811\n",
            "4769\n",
            "5437\n",
            "596\n",
            "594\n",
            "5431\n",
            "1481\n",
            "5433\n",
            "592\n",
            "3919\n",
            "3274\n",
            "3276\n",
            "3268\n",
            "3264\n",
            "3263\n",
            "586\n",
            "1825\n",
            "1827\n",
            "3921\n",
            "3275\n",
            "3279\n",
            "982\n",
            "5413\n",
            "983\n",
            "3309\n",
            "3308\n",
            "5408\n",
            "4761\n",
            "3303\n",
            "3298\n",
            "984\n",
            "1820\n",
            "3901\n",
            "3905\n",
            "3910\n",
            "5419\n",
            "1483\n",
            "3284\n",
            "3282\n",
            "534\n",
            "532\n",
            "4035\n",
            "422\n",
            "5671\n",
            "440\n",
            "439\n",
            "5674\n",
            "4013\n",
            "1043\n",
            "5678\n",
            "5679\n",
            "4017\n",
            "3035\n",
            "5685\n",
            "3711\n",
            "4656\n",
            "5688\n",
            "3029\n",
            "4654\n",
            "4652\n",
            "5670\n",
            "4012\n",
            "5668\n",
            "450\n",
            "3071\n",
            "1963\n",
            "1417\n",
            "3058\n",
            "5649\n",
            "5651\n",
            "4009\n",
            "4666\n",
            "1979\n",
            "5656\n",
            "4011\n",
            "5658\n",
            "1968\n",
            "1969\n",
            "443\n",
            "3044\n",
            "1983\n",
            "1986\n",
            "3144\n",
            "5697\n",
            "5727\n",
            "2004\n",
            "4024\n",
            "2005\n",
            "403\n",
            "2006\n",
            "1068\n",
            "2009\n",
            "1403\n",
            "4027\n",
            "5739\n",
            "5740\n",
            "4029\n",
            "4030\n",
            "4031\n",
            "1401\n",
            "4033\n",
            "2995\n",
            "2996\n",
            "1065\n",
            "1060\n",
            "4651\n",
            "421\n",
            "3020\n",
            "4644\n",
            "4022\n",
            "1059\n",
            "416\n",
            "5709\n",
            "2002\n",
            "415\n",
            "3009\n",
            "1996\n",
            "3006\n",
            "1062\n",
            "2001\n",
            "5720\n",
            "1042\n",
            "4671\n",
            "5638\n",
            "1421\n",
            "5569\n",
            "5570\n",
            "1443\n",
            "5573\n",
            "3120\n",
            "1925\n",
            "3118\n",
            "1926\n",
            "5578\n",
            "1025\n",
            "3972\n",
            "495\n",
            "3111\n",
            "1928\n",
            "5586\n",
            "5587\n",
            "5588\n",
            "502\n",
            "504\n",
            "1924\n",
            "1019\n",
            "5545\n",
            "4699\n",
            "4698\n",
            "1017\n",
            "3138\n",
            "1920\n",
            "528\n",
            "4694\n",
            "3126\n",
            "520\n",
            "5557\n",
            "512\n",
            "5559\n",
            "508\n",
            "1921\n",
            "5564\n",
            "5589\n",
            "3109\n",
            "1933\n",
            "1427\n",
            "1952\n",
            "5619\n",
            "5620\n",
            "3085\n",
            "5624\n",
            "1955\n",
            "5626\n",
            "5628\n",
            "1947\n",
            "463\n",
            "1957\n",
            "462\n",
            "5633\n",
            "5634\n",
            "1958\n",
            "3997\n",
            "3989\n",
            "5615\n",
            "1936\n",
            "1944\n",
            "3104\n",
            "5595\n",
            "482\n",
            "3975\n",
            "1029\n",
            "3984\n",
            "479\n",
            "5603\n",
            "473\n",
            "477\n",
            "3094\n",
            "1035\n",
            "5609\n",
            "3093\n",
            "475\n",
            "474\n",
            "5355\n",
            "1794\n",
            "4786\n",
            "1560\n",
            "3583\n",
            "5091\n",
            "3580\n",
            "3578\n",
            "1670\n",
            "5095\n",
            "1672\n",
            "795\n",
            "3572\n",
            "3571\n",
            "3569\n",
            "1563\n",
            "3564\n",
            "4905\n",
            "1679\n",
            "1562\n",
            "3764\n",
            "1668\n",
            "5088\n",
            "4908\n",
            "1565\n",
            "901\n",
            "5071\n",
            "1655\n",
            "3610\n",
            "5074\n",
            "3750\n",
            "3752\n",
            "4912\n",
            "1667\n",
            "5079\n",
            "1659\n",
            "5081\n",
            "3757\n",
            "904\n",
            "3598\n",
            "3595\n",
            "4902\n",
            "4899\n",
            "3877\n",
            "3766\n",
            "3538\n",
            "3771\n",
            "3777\n",
            "1698\n",
            "3781\n",
            "921\n",
            "1556\n",
            "5144\n",
            "923\n",
            "4877\n",
            "5147\n",
            "5148\n",
            "925\n",
            "926\n",
            "927\n",
            "4869\n",
            "1709\n",
            "1558\n",
            "3539\n",
            "1692\n",
            "1684\n",
            "3554\n",
            "4897\n",
            "3553\n",
            "4896\n",
            "5116\n",
            "3551\n",
            "913\n",
            "5120\n",
            "5130\n",
            "782\n",
            "5122\n",
            "1687\n",
            "914\n",
            "3767\n",
            "4888\n",
            "3542\n",
            "5069\n",
            "803\n",
            "4923\n",
            "1570\n",
            "3729\n",
            "5000\n",
            "5001\n",
            "842\n",
            "3730\n",
            "1612\n",
            "839\n",
            "5006\n",
            "836\n",
            "3732\n",
            "1613\n",
            "832\n",
            "1615\n",
            "879\n",
            "1580\n",
            "4950\n",
            "5016\n",
            "878\n",
            "4957\n",
            "851\n",
            "3702\n",
            "4975\n",
            "3716\n",
            "4977\n",
            "3717\n",
            "1585\n",
            "861\n",
            "3703\n",
            "1598\n",
            "4958\n",
            "1583\n",
            "4960\n",
            "1601\n",
            "877\n",
            "3692\n",
            "1602\n",
            "1604\n",
            "3671\n",
            "884\n",
            "885\n",
            "5056\n",
            "1640\n",
            "3631\n",
            "891\n",
            "3739\n",
            "811\n",
            "893\n",
            "1641\n",
            "1645\n",
            "3636\n",
            "3622\n",
            "808\n",
            "1647\n",
            "3742\n",
            "1651\n",
            "4928\n",
            "805\n",
            "4934\n",
            "3637\n",
            "1622\n",
            "886\n",
            "1623\n",
            "3666\n",
            "5027\n",
            "1573\n",
            "827\n",
            "1626\n",
            "3662\n",
            "3659\n",
            "4935\n",
            "3654\n",
            "825\n",
            "3652\n",
            "3647\n",
            "1634\n",
            "1572\n",
            "3639\n",
            "1710\n",
            "5157\n",
            "1552\n",
            "3418\n",
            "686\n",
            "960\n",
            "4813\n",
            "1759\n",
            "1518\n",
            "1517\n",
            "3847\n",
            "4809\n",
            "5296\n",
            "3394\n",
            "1770\n",
            "5302\n",
            "3390\n",
            "963\n",
            "5306\n",
            "5307\n",
            "3852\n",
            "959\n",
            "4817\n",
            "5283\n",
            "698\n",
            "4822\n",
            "5263\n",
            "5264\n",
            "5265\n",
            "1519\n",
            "5268\n",
            "700\n",
            "4819\n",
            "687\n",
            "1750\n",
            "3409\n",
            "5277\n",
            "688\n",
            "3406\n",
            "4818\n",
            "5281\n",
            "1771\n",
            "4805\n",
            "966\n",
            "1784\n",
            "5334\n",
            "3365\n",
            "1512\n",
            "661\n",
            "5338\n",
            "3362\n",
            "4792\n",
            "3356\n",
            "1515\n",
            "5343\n",
            "5344\n",
            "3872\n",
            "1789\n",
            "651\n",
            "3351\n",
            "649\n",
            "1779\n",
            "3369\n",
            "676\n",
            "3379\n",
            "3854\n",
            "3855\n",
            "5316\n",
            "672\n",
            "671\n",
            "3381\n",
            "1774\n",
            "3860\n",
            "3370\n",
            "668\n",
            "3377\n",
            "4797\n",
            "3374\n",
            "4796\n",
            "5328\n",
            "1777\n",
            "3417\n",
            "1521\n",
            "5161\n",
            "4825\n",
            "3484\n",
            "3483\n",
            "938\n",
            "5189\n",
            "5191\n",
            "1534\n",
            "1727\n",
            "5196\n",
            "3472\n",
            "3464\n",
            "5200\n",
            "3463\n",
            "3461\n",
            "3460\n",
            "744\n",
            "3812\n",
            "1530\n",
            "3486\n",
            "1716\n",
            "4855\n",
            "758\n",
            "760\n",
            "5163\n",
            "3504\n",
            "3787\n",
            "759\n",
            "3502\n",
            "4866\n",
            "3498\n",
            "3803\n",
            "5171\n",
            "932\n",
            "5173\n",
            "3791\n",
            "1546\n",
            "4861\n",
            "3489\n",
            "1737\n",
            "1740\n",
            "739\n",
            "710\n",
            "5236\n",
            "720\n",
            "3435\n",
            "3829\n",
            "1746\n",
            "3433\n",
            "4832\n",
            "4831\n",
            "3828\n",
            "4830\n",
            "3429\n",
            "3427\n",
            "1524\n",
            "5251\n",
            "3423\n",
            "5253\n",
            "3439\n",
            "4837\n",
            "3453\n",
            "3818\n",
            "5212\n",
            "3450\n",
            "737\n",
            "5216\n",
            "3816\n",
            "735\n",
            "3447\n",
            "Epoch 1/32\n",
            "6400/6400 [==============================] - 1s 168us/sample - loss: 0.6403 - accuracy: 0.7159\n",
            "Epoch 2/32\n",
            "6400/6400 [==============================] - 1s 146us/sample - loss: 0.4906 - accuracy: 0.7833\n",
            "Epoch 3/32\n",
            "6400/6400 [==============================] - 1s 146us/sample - loss: 0.4249 - accuracy: 0.8111\n",
            "Epoch 4/32\n",
            "6400/6400 [==============================] - 1s 143us/sample - loss: 0.3914 - accuracy: 0.8208\n",
            "Epoch 5/32\n",
            "6400/6400 [==============================] - 1s 144us/sample - loss: 0.3729 - accuracy: 0.8281\n",
            "Epoch 6/32\n",
            "6400/6400 [==============================] - 1s 141us/sample - loss: 0.3502 - accuracy: 0.8355\n",
            "Epoch 7/32\n",
            "6400/6400 [==============================] - 1s 142us/sample - loss: 0.3303 - accuracy: 0.8480\n",
            "Epoch 8/32\n",
            "6400/6400 [==============================] - 1s 144us/sample - loss: 0.3219 - accuracy: 0.8512\n",
            "Epoch 9/32\n",
            "6400/6400 [==============================] - 1s 143us/sample - loss: 0.3071 - accuracy: 0.8623\n",
            "Epoch 10/32\n",
            "6400/6400 [==============================] - 1s 143us/sample - loss: 0.2970 - accuracy: 0.8681\n",
            "Epoch 11/32\n",
            "6400/6400 [==============================] - 1s 144us/sample - loss: 0.2819 - accuracy: 0.8756\n",
            "Epoch 12/32\n",
            "6400/6400 [==============================] - 1s 141us/sample - loss: 0.2721 - accuracy: 0.8830\n",
            "Epoch 13/32\n",
            "6400/6400 [==============================] - 1s 145us/sample - loss: 0.2609 - accuracy: 0.8861\n",
            "Epoch 14/32\n",
            "6400/6400 [==============================] - 1s 144us/sample - loss: 0.2613 - accuracy: 0.8820\n",
            "Epoch 15/32\n",
            "6400/6400 [==============================] - 1s 144us/sample - loss: 0.2522 - accuracy: 0.8895\n",
            "Epoch 16/32\n",
            "6400/6400 [==============================] - 1s 149us/sample - loss: 0.2481 - accuracy: 0.8919\n",
            "Epoch 17/32\n",
            "6400/6400 [==============================] - 1s 142us/sample - loss: 0.2448 - accuracy: 0.8898\n",
            "Epoch 18/32\n",
            "6400/6400 [==============================] - 1s 145us/sample - loss: 0.2376 - accuracy: 0.8947\n",
            "Epoch 19/32\n",
            "6400/6400 [==============================] - 1s 142us/sample - loss: 0.2345 - accuracy: 0.8984\n",
            "Epoch 20/32\n",
            "6400/6400 [==============================] - 1s 148us/sample - loss: 0.2350 - accuracy: 0.8933\n",
            "Epoch 21/32\n",
            "6400/6400 [==============================] - 1s 148us/sample - loss: 0.2308 - accuracy: 0.9011\n",
            "Epoch 22/32\n",
            "6400/6400 [==============================] - 1s 143us/sample - loss: 0.2284 - accuracy: 0.8970\n",
            "Epoch 23/32\n",
            "6400/6400 [==============================] - 1s 145us/sample - loss: 0.2228 - accuracy: 0.9033\n",
            "Epoch 24/32\n",
            "6400/6400 [==============================] - 1s 144us/sample - loss: 0.2234 - accuracy: 0.8998\n",
            "Epoch 25/32\n",
            "6400/6400 [==============================] - 1s 141us/sample - loss: 0.2161 - accuracy: 0.9045\n",
            "Epoch 26/32\n",
            "6400/6400 [==============================] - 1s 142us/sample - loss: 0.2179 - accuracy: 0.9020\n",
            "Epoch 27/32\n",
            "6400/6400 [==============================] - 1s 144us/sample - loss: 0.2153 - accuracy: 0.9023\n",
            "Epoch 28/32\n",
            "6400/6400 [==============================] - 1s 143us/sample - loss: 0.2175 - accuracy: 0.9016\n",
            "Epoch 29/32\n",
            "6400/6400 [==============================] - 1s 141us/sample - loss: 0.2152 - accuracy: 0.8989\n",
            "Epoch 30/32\n",
            "6400/6400 [==============================] - 1s 140us/sample - loss: 0.2161 - accuracy: 0.9006\n",
            "Epoch 31/32\n",
            "6400/6400 [==============================] - 1s 141us/sample - loss: 0.2101 - accuracy: 0.9048\n",
            "Epoch 32/32\n",
            "6400/6400 [==============================] - 1s 142us/sample - loss: 0.2117 - accuracy: 0.9044\n",
            "Accuracy 0.81875  Precision  0.8663793103448276  Recall  0.75375  F1  0.8061497326203209\n",
            "Saving Results at /content/gdrive/My Drive/ML/APKAnalysis/Results/mixP0.1-size8000-stratEMixStrategy.Furthest_Bounds.csv!\n",
            "Saving checkpoint at  /content/gdrive/My Drive/ML/APKAnalysis/Checkpoints/EMixStrategy.Furthest_Bounds_SVM\n",
            "Saving scores at:  /content/gdrive/My Drive/ML/APKAnalysis/Scores/FurthestBoundSVMScores\n",
            "Epoch 1/32\n",
            "6400/6400 [==============================] - 1s 159us/sample - loss: 0.6317 - accuracy: 0.7242\n",
            "Epoch 2/32\n",
            "6400/6400 [==============================] - 1s 136us/sample - loss: 0.5071 - accuracy: 0.7591\n",
            "Epoch 3/32\n",
            "6400/6400 [==============================] - 1s 133us/sample - loss: 0.4614 - accuracy: 0.7916\n",
            "Epoch 4/32\n",
            "6400/6400 [==============================] - 1s 137us/sample - loss: 0.4282 - accuracy: 0.8022\n",
            "Epoch 5/32\n",
            "6400/6400 [==============================] - 1s 140us/sample - loss: 0.3933 - accuracy: 0.8253\n",
            "Epoch 6/32\n",
            "6400/6400 [==============================] - 1s 135us/sample - loss: 0.3636 - accuracy: 0.8389\n",
            "Epoch 7/32\n",
            "6400/6400 [==============================] - 1s 135us/sample - loss: 0.3333 - accuracy: 0.8552\n",
            "Epoch 8/32\n",
            "6400/6400 [==============================] - 1s 137us/sample - loss: 0.3122 - accuracy: 0.8648\n",
            "Epoch 9/32\n",
            "6400/6400 [==============================] - 1s 139us/sample - loss: 0.2986 - accuracy: 0.8767\n",
            "Epoch 10/32\n",
            "6400/6400 [==============================] - 1s 142us/sample - loss: 0.2826 - accuracy: 0.8844\n",
            "Epoch 11/32\n",
            "6400/6400 [==============================] - 1s 135us/sample - loss: 0.2685 - accuracy: 0.8906\n",
            "Epoch 12/32\n",
            "6400/6400 [==============================] - 1s 139us/sample - loss: 0.2640 - accuracy: 0.8897\n",
            "Epoch 13/32\n",
            "6400/6400 [==============================] - 1s 135us/sample - loss: 0.2569 - accuracy: 0.8950\n",
            "Epoch 14/32\n",
            "6400/6400 [==============================] - 1s 134us/sample - loss: 0.2488 - accuracy: 0.8988\n",
            "Epoch 15/32\n",
            "6400/6400 [==============================] - 1s 138us/sample - loss: 0.2417 - accuracy: 0.9008\n",
            "Epoch 16/32\n",
            "6400/6400 [==============================] - 1s 143us/sample - loss: 0.2397 - accuracy: 0.9047\n",
            "Epoch 17/32\n",
            "6400/6400 [==============================] - 1s 143us/sample - loss: 0.2301 - accuracy: 0.9044\n",
            "Epoch 18/32\n",
            "6400/6400 [==============================] - 1s 136us/sample - loss: 0.2298 - accuracy: 0.9075\n",
            "Epoch 19/32\n",
            "6400/6400 [==============================] - 1s 136us/sample - loss: 0.2231 - accuracy: 0.9111\n",
            "Epoch 20/32\n",
            "6400/6400 [==============================] - 1s 135us/sample - loss: 0.2255 - accuracy: 0.9084\n",
            "Epoch 21/32\n",
            "6400/6400 [==============================] - 1s 135us/sample - loss: 0.2190 - accuracy: 0.9080\n",
            "Epoch 22/32\n",
            "6400/6400 [==============================] - 1s 139us/sample - loss: 0.2091 - accuracy: 0.9172\n",
            "Epoch 23/32\n",
            "6400/6400 [==============================] - 1s 139us/sample - loss: 0.2089 - accuracy: 0.9189\n",
            "Epoch 24/32\n",
            "6400/6400 [==============================] - 1s 136us/sample - loss: 0.2077 - accuracy: 0.9178\n",
            "Epoch 25/32\n",
            "6400/6400 [==============================] - 1s 135us/sample - loss: 0.2059 - accuracy: 0.9169\n",
            "Epoch 26/32\n",
            "6400/6400 [==============================] - 1s 138us/sample - loss: 0.2111 - accuracy: 0.9187\n",
            "Epoch 27/32\n",
            "6400/6400 [==============================] - 1s 138us/sample - loss: 0.1983 - accuracy: 0.9214\n",
            "Epoch 28/32\n",
            "6400/6400 [==============================] - 1s 144us/sample - loss: 0.2039 - accuracy: 0.9205\n",
            "Epoch 29/32\n",
            "6400/6400 [==============================] - 1s 147us/sample - loss: 0.1894 - accuracy: 0.9269\n",
            "Epoch 30/32\n",
            "6400/6400 [==============================] - 1s 148us/sample - loss: 0.1906 - accuracy: 0.9233\n",
            "Epoch 31/32\n",
            "6400/6400 [==============================] - 1s 145us/sample - loss: 0.1895 - accuracy: 0.9255\n",
            "Epoch 32/32\n",
            "6400/6400 [==============================] - 1s 145us/sample - loss: 0.1856 - accuracy: 0.9272\n",
            "Accuracy 0.81875  Precision  0.839095744680851  Recall  0.78875  F1  0.8131443298969072\n",
            "Saving Results at /content/gdrive/My Drive/ML/APKAnalysis/Results/mixP0.1-size8000-stratEMixStrategy.Furthest_Bounds_SVM.csv!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yHJWOoFeX48A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " cmodel.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YMDc0ZfNaKc7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Poisoning on already trained dataset\n",
        "\n",
        "---\n",
        "\n",
        "Here we explore the effects of using the label flipping techniques when we use our dataset to train the model initially, and then we use data poisoning on a new half which we will train and test upon.  We overwite the old variables so they'll get garbage collected"
      ]
    },
    {
      "metadata": {
        "id": "6HJzM56qa_iH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocess Full Dataset"
      ]
    },
    {
      "metadata": {
        "id": "CZ7C1znpaQaF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ben_samples = []\n",
        "mal_samples = []\n",
        "\n",
        "with open(GOOD_PATH_FULL, encoding='utf-8') as f:\n",
        "  ben_samples += f.readlines()\n",
        "with open(BAD_PATH_FULL, encoding='utf-8') as f:\n",
        "  mal_samples += f.readlines()\n",
        "  \n",
        "samples = ben_samples + mal_samples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wSZSI8j0cMLD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ben_samples_count = len(ben_samples)\n",
        "mal_samples_count = len(mal_samples)\n",
        "sample_count = ben_samples_count if ben_samples_count < mal_samples_count else mal_samples_count\n",
        "sample_count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Go2DzrEod39T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "type(ben_samples[1:2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VKY1MR3MNf2C",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Add labels\n",
        "labels = np.array([])\n",
        "for x in ben_samples[:sample_count]:\n",
        "  labels = np.append(labels, 0)\n",
        "for x in mal_samples[:sample_count]:\n",
        "  labels = np.append(labels, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SjmOB_IxatqX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "len(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UI5UBM4CB9cK",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Wordcount one-hot transformer\n",
        "perm_vect = CountVectorizer(analyzer=partial(regexp_tokenize, pattern=perm_pattern))\n",
        "feat_vect = CountVectorizer(analyzer=partial(regexp_tokenize, pattern=feat_pattern))                                                                       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PomP5hNGB9cq",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Set vocabulry before transformation\n",
        "perm_vect.vocabulary_ = perm_vocab\n",
        "feat_vect.vocabulary_ = feat_vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "nXErfJJJB9cy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Generate the one-hot vectors now \n",
        "perm_input_sparse = perm_vect.transform(samples)\n",
        "feat_input_sparse = feat_vect.transform(samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aoIc896wB9c4",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#To numpy array for easier use\n",
        "perm_inputs = perm_input_sparse.toarray()\n",
        "feat_inputs = feat_input_sparse.toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zpEAYujCegIs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Size of the splits of the data (one we use for training a good classifier, one we use for poisoning)\n",
        "poison_split_size = int(len(labels)/4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "USXRIJa6kyC5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "type(perm_inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rC9GSlMEEgtE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "perm_inputs_norm = perm_inputs[:poison_split_size]\n",
        "perm_inputs_poison = feat_inputs[:poison_split_size] \n",
        "feat_inputs_norm = perm_inputs[poison_split_size:]\n",
        "feat_inputs_norm = feat_inputs[poison_split_size:] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bb-z1gsOafv4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "len(perm_inputs_norm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "97fQ1V4U1Smk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Further Analysis on Model Performance\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Here we are looking into the data flipping process and trying to find the physical meaning behind the results"
      ]
    },
    {
      "metadata": {
        "id": "bRxWbbLOgoix",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_y-qMGJZ8tiA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## tf.function performance vs keras\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Testing out if we get any accuracy differences between two different ways to create a model in TensorFlow.  Whatever leads to the best accuracy will be the model we use to perform some of our label flipping techniques on."
      ]
    },
    {
      "metadata": {
        "id": "xE3jKA7G8p2v",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#tf.function to train model\n",
        "f\n",
        "train_accuracy = tf.keras.metrics.BinaryAccuracy()\n",
        "test_accuracy = tf.keras.metrics.BinaryAccuracy()\n",
        "\n",
        "model=createModel()\n",
        "\n",
        "#Use tensorflow datasets to pass in information to tf.function\n",
        "dataset_train = tf.data.Dataset.from_tensor_slices(\n",
        "  (\n",
        "    perm_train,\n",
        "    feat_train,\n",
        "    np.array(labels_train).reshape(-1,1)\n",
        "  )\n",
        ")\n",
        "\n",
        "dataset_test = tf.data.Dataset.from_tensor_slices(\n",
        "  (\n",
        "    perm_test,\n",
        "    feat_test,\n",
        "    np.array(labels_test).reshape(-1,1)\n",
        "  )\n",
        ")\n",
        "\n",
        "dataset_batch = dataset_train.shuffle(perm_train.shape[0]).batch(32) #Train the model as normally first\n",
        "dataset_test_batch = dataset_test.shuffle(perm_train.shape[0]).batch(32) #Test set to ensure we did not screw up the model\n",
        "\n",
        "#Training and testing with tf.function\n",
        "template = 'Epoch {}, Loss: {}, Accuracy: {}'\n",
        "for epoch in range(EPOCHS):\n",
        "  for perm, feat, y in dataset_batch:\n",
        "    train_step(perm,feat,y)\n",
        "  print(template.format(epoch+1, train_loss.result(), train_accuracy.result() * 100))\n",
        "  \n",
        "template = 'Test Accuracy {}'\n",
        "for perm, feat, y in dataset_test_batch:\n",
        "    test_step(perm, feat, y)\n",
        "print(template.format(test_accuracy.result() * 100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kBylmvpm4sE5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# #Train best case model and save as a checkpoint\n",
        "# model = createModel()\n",
        "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# model.fit([perm_train, feat_train], labels_train, epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
        "# labels_pred = model.predict([perm_test, feat_test], batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xo08PzmUNnle",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# #Test accuracy of keras model\n",
        "# test_accuracy = tf.keras.metrics.BinaryAccuracy()\n",
        "# test_accuracy(labels_test, labels_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NAM9Vrl-9po8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# #Save best model as final result\n",
        "# checkpoint = tf.train.Checkpoint(model=model)\n",
        "# checkpoint.save(os.path.join(CHKPT_PATH, \"FinalResult\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hG_Sfdl5YNkw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# If we restore a model created via keras fit we need to make sure to compile our dummy model\n",
        "# model = createModel()\n",
        "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# model.layers[1].get_weights()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SXKeWzHB-zhP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Conclusion: They give about the same performance... at least for this relatively simple case"
      ]
    },
    {
      "metadata": {
        "id": "j_TJFkuXU3GY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Analyzing error types"
      ]
    },
    {
      "metadata": {
        "id": "dDm2DIbdyjhG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(mat):\n",
        "  fig = plt.figure(figsize=(8,8))\n",
        "  plt.matshow(mat, cmap=plt.get_cmap('YlGn'))\n",
        "  plt.colorbar()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SmlffdqqzlQ2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = createModel()\n",
        "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "checkpoint = tf.train.Checkpoint(model=model)\n",
        "checkpoint.restore(os.path.join(CHKPT_PATH, \"FinalResult-1\"))\n",
        "labels_pred = model.predict([perm_test, feat_test], batch_size=BATCH_SIZE)\n",
        "labels_pred = (labels_pred > 0.5)                            \n",
        "cm = confusion_matrix(labels_test, labels_pred)\n",
        "cm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yPQZgR3BDMV1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(cm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BemCdnv4ADcO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "labels_pred = model.predict([perm_test, feat_test], batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2afrw8q0DmXg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "incorrect = (labels_test != labels_pred.reshape(1,-1))\n",
        "np.unique(incorrect, return_counts=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QDGFXb_GnaZ9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Analyzing Decision Boundary"
      ]
    },
    {
      "metadata": {
        "id": "CAlgQBZzncyU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}